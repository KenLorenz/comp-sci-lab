{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *\n",
    "import tensorflow as tf\n",
    "from document_utils import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_x_train()\n",
    "x_test = load_x_test()\n",
    "y_train = load_y_train()\n",
    "y_test = load_y_test()\n",
    "\n",
    "verify_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A-Z dataset graph\n",
    "csv_file= pd.read_csv('main_dataset/A_Z Handwritten Data.csv').astype('float32')\n",
    "        \n",
    "dataset = pd.DataFrame(csv_file)\n",
    "\n",
    "x = dataset.drop('0', axis = 1)\n",
    "y = dataset['0']\n",
    "\n",
    "word_dict = {\n",
    "    0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'\n",
    "}\n",
    "\n",
    "y_integer = np.intp(y)\n",
    "count = np.zeros(26, dtype = 'int')\n",
    "\n",
    "for i in y_integer:\n",
    "    count[i] += 1\n",
    "    \n",
    "alphabets = []\n",
    "\n",
    "for i in word_dict.values():\n",
    "    alphabets.append(i)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize = (8, 8))\n",
    "ax.barh(alphabets, count)\n",
    "\n",
    "plt.xlabel('Number Of Each Alphabets', fontsize = 8)\n",
    "plt.ylabel('Alphabets', fontsize = 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model testing\n",
    "\n",
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(784,)),\n",
    "        \n",
    "        Dense(126, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(26, activation='softmax')\n",
    "        \n",
    "    ], name = \"old_model\" \n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# callback = EarlyStopping(monitor='loss', patience=3) , callbacks=[callback]\n",
    "history = model.fit(x_train, y_train, validation_split = 0.1, epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('training loss')\n",
    "plt.ylabel('training loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('training accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0.0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "\n",
    "for i in range(len(lambdas)):\n",
    "    lambda_ = lambdas[i]\n",
    "    model = Sequential(\n",
    "        [               \n",
    "            tf.keras.Input(shape=(784,)),\n",
    "            \n",
    "            Dense(126, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
    "            Dense(64, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(lambda_)),\n",
    "            Dense(26, activation='softmax')\n",
    "            \n",
    "        ], name = \"my_stupid_model\" \n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    history = model.fit(x_train, y_train, validation_split = 0.1, epochs=100)\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('training loss')\n",
    "    plt.ylabel('training loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('training accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
